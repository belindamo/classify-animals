{"id":"aliyu2025african","title":"Evaluating Deep Learning Models for African Wildlife Image Classification: From DenseNet to Vision Transformers","authors":"Lukman Jibril Aliyu, Umar Sani Muhammad, Bilqisu Ismail, Nasiru Muhammad, Almustapha A Wakili, Seid Muhie Yimam, Shamsuddeen Hassan Muhammad, Mustapha Abdullahi","journal":"arXiv","year":"2025","doi":"arXiv:2507.21364","url":"https://arxiv.org/abs/2507.21364","keyAssumptions":"Standard computer vision models can be directly applied to wildlife monitoring without domain-specific considerations","keyHypotheses":"Different architectures have vastly different performance characteristics in wildlife domains, with trade-offs between accuracy and computational cost","strengths":"Comprehensive comparison across major architectures; practical deployment considerations; real-world application","weaknesses":"Limited to 4 species; computational cost analysis could be more detailed","citation":"Aliyu, L. J., et al. (2025). Evaluating Deep Learning Models for African Wildlife Image Classification: From DenseNet to Vision Transformers. arXiv:2507.21364.","notes":"ViT-H/14 achieved 99% accuracy vs DenseNet-201 at 67%, but with significantly higher computational costs. Deployed to Hugging Face Gradio Space.","addedDate":"2025-08-21T23:27:15.000Z"}
{"id":"sankaran2024multi","title":"Multi-Species Object Detection in Drone Imagery for Population Monitoring of Endangered Animals","authors":"Sankaran, Sowmya","journal":"arXiv","year":"2024","doi":"arXiv:2407.00127","url":"https://arxiv.org/abs/2407.00127","keyAssumptions":"General object detection models like baseline YOLOv8 work well on drone imagery of wildlife","keyHypotheses":"Fine-tuning with domain-specific data can dramatically improve performance for wildlife detection","strengths":"Dramatic performance improvement (0.7% to 95%); edge deployment on Jetson Orin Nano; real-world applicability","weaknesses":"Limited species diversity in evaluation; deployment testing could be more extensive","citation":"Sankaran, S. (2024). Multi-Species Object Detection in Drone Imagery for Population Monitoring of Endangered Animals. arXiv:2407.00127.","notes":"30 different models trained, largest with 43.7M parameters. Successful deployment for real-time species detection.","addedDate":"2025-08-21T23:27:15.000Z"}
{"id":"muthivhi2025wildlife","title":"Improving Wildlife Out-of-Distribution Detection: Africa's Big Five","authors":"Mufhumudzi Muthivhi, Fredrik Gustafsson, Terence L. van Zyl","journal":"arXiv","year":"2025","doi":"arXiv:2506.06719","url":"https://arxiv.org/abs/2506.06719","keyAssumptions":"Closed-world classification models can safely operate in open wildlife environments","keyHypotheses":"Feature-based OOD methods can provide safer deployment in open-world wildlife scenarios","strengths":"Addresses critical safety concerns; comprehensive OOD evaluation; practical importance for human-wildlife conflict","weaknesses":"Limited to Big Five species; more diverse OOD scenarios needed","citation":"Muthivhi, M., Gustafsson, F., & van Zyl, T. L. (2025). Improving Wildlife Out-of-Distribution Detection: Africa's Big Five. arXiv:2506.06719.","notes":"NCM with ImageNet features achieved significant improvements in AUPR-IN, AUPR-OUT and AUTC metrics.","addedDate":"2025-08-21T23:27:15.000Z"}
{"id":"shinoda2025animalclue","title":"AnimalClue: Recognizing Animals by their Traces","authors":"Risa Shinoda, Nakamasa Inoue, Iro Laina, Christian Rupprecht, Hirokatsu Kataoka","journal":"arXiv","year":"2025","doi":"arXiv:2507.20240","url":"https://arxiv.org/abs/2507.20240","keyAssumptions":"Direct visual features (animal appearances) are sufficient for wildlife monitoring","keyHypotheses":"Indirect evidence (footprints, feces, etc.) can provide valuable information for species identification","strengths":"First large-scale indirect evidence dataset; novel research direction; comprehensive species coverage (968 species)","weaknesses":"Limited evaluation on real-world deployment scenarios; integration with direct visual methods unclear","citation":"Shinoda, R., et al. (2025). AnimalClue: Recognizing Animals by their Traces. arXiv:2507.20240.","notes":"159,605 bounding boxes across 5 categories of indirect evidence. Opens new research direction beyond direct visual classification.","addedDate":"2025-08-21T23:27:15.000Z"}
{"id":"boscoe2025green","title":"GreenCrossingAI: A Camera Trap/Computer Vision Pipeline for Environmental Science Research Groups","authors":"Bernie Boscoe, Shawn Johnson, Andrea Osbon, Chandler Campbell, Karen Mager","journal":"arXiv","year":"2025","doi":"arXiv:2507.09410","url":"https://arxiv.org/abs/2507.09410","keyAssumptions":"Large-scale, resource-intensive solutions are necessary for effective camera trap processing","keyHypotheses":"Low-resource, on-premise pipelines can effectively serve small research groups","strengths":"Practical framework for resource-constrained groups; comprehensive pipeline design; real-world focus","weaknesses":"Limited performance comparisons with high-resource alternatives; scalability questions","citation":"Boscoe, B., et al. (2025). GreenCrossingAI: A Camera Trap/Computer Vision Pipeline for Environmental Science Research Groups. arXiv:2507.09410.","notes":"Addresses challenges of data volume, labeling, environmental variability, and ML/AI integration for small research groups.","addedDate":"2025-08-21T23:27:15.000Z"}